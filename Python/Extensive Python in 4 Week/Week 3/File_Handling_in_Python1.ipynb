{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f58dfb5d",
   "metadata": {},
   "source": [
    "### Python File Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec070bb",
   "metadata": {},
   "source": [
    "Python supports file handling and allows users to handle files i.e., to read and write files, along with many other file handling options, to operate on files. Python make the concept of file handling easy and short. Python treats files differently as text or binary and this is important to note. Each line of code includes a sequence of characters and they form a text file. Each line of a file is terminated with a special character, called the EOL or End of Line characters like comma {,} or newline character. It ends the current line and tells the interpreter a new one has begun. Let’s start with the reading and writing files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c83134",
   "metadata": {},
   "source": [
    "#### Using the open() function\n",
    "\n",
    "Before performing any operation on the file like reading or writing, first, we have to open that file. For this, we should use Python’s inbuilt function open() but at the time of opening, we have to specify the mode, which represents the purpose of the opening file.\n",
    "\n",
    "```python\n",
    "f = open(filename, mode)\n",
    "```\n",
    "\n",
    "Where the following mode is supported:\n",
    "\n",
    "1. r: open an existing file for a read operation.\n",
    "2. w: open an existing file for a write operation. If the file already contains some data then it will be overridden but if the file is not present then it creates the file as well.\n",
    "3. a:  open an existing file for append operation. It won’t override existing data.\n",
    "4. r+:  To read and write data into the file. The previous data in the file will be overridden.\n",
    "5. w+: To write and read data. It will override existing data.\n",
    "6. a+: To append and read data from the file. It won’t override existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a9ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a file named \"extensivepythonfundamentals.txt\", will be opened with the reading mode.\n",
    "file = open('extensivepythonfundamentals.txt', 'r')\n",
    "# This will print every line one by one in the file\n",
    "for each in file:\n",
    "    print (each)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8337807",
   "metadata": {},
   "source": [
    "The open command will open the file in the read mode and the for loop will print each line present in the file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac22ec6e",
   "metadata": {},
   "source": [
    "#### Using the `read()` mode\n",
    "\n",
    "There is more than one way to read a file in Python. If you need to extract a string that contains all characters in the file then we can use file.read(). The full code would work like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998052e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code to illustrate read() mode\n",
    "file = open(\"extensivepythonfundamentals.txt\", \"r\")\n",
    "print (file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eee4b1",
   "metadata": {},
   "source": [
    "#### Creating a file using write() mode\n",
    "\n",
    "Let’s see how to create a file and how to write mode works, so in order to manipulate the file, write the following in your Python environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a12f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code to create a file\n",
    "file = open('samplefile.txt','w')\n",
    "file.write(\"This is the write command\")\n",
    "file.write(\"It allows us to write in a particular file\")\n",
    "file.close()\n",
    "\n",
    "#The close() command terminates all the resources in use and frees \n",
    "#the system of this particular program. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca9243",
   "metadata": {},
   "source": [
    "#### Working with the append() mode\n",
    "\n",
    "Let us see how the append mode works: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f637161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code to illustrate append() mode\n",
    "file = open('samplefile.txt', 'a')\n",
    "file.write(\"This will add this line\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90032f20",
   "metadata": {},
   "source": [
    "There are also various other commands in file handling that is used to handle various tasks like: \n",
    "\n",
    "- rstrip(): This function strips each line of a file off spaces from the right-hand side. i.e. it reemoves any white spaces at the end of the string: So, the rstrip() method removes any trailing characters (characters at the end a string), space is the default trailing character to remove.\n",
    "\n",
    "Syntax is:\n",
    "\n",
    "```python\n",
    "string.rstrip(characters)\n",
    "```\n",
    "\n",
    "```python\n",
    "txt = \"     banana     \"\n",
    "x = txt.rstrip()\n",
    "print(\"of all fruits\", x, \"is my favorite\")\n",
    "```\n",
    "```python\n",
    "txt = \"banana,,,,,ssqqqww.....\"\n",
    "x = txt.rstrip(\",.qsw\")\n",
    "print(x)\n",
    "```\n",
    "- lstrip(): This function strips each line of a file off spaces from the left-hand side.\n",
    "\n",
    "```python\n",
    "string.rstrip(characters)\n",
    "```\n",
    "\n",
    "```python\n",
    "txt = \"     banana     \"\n",
    "x = txt.lstrip()\n",
    "print(\"of all fruits\", x, \"is my favorite\")\n",
    "```\n",
    "```python\n",
    "txt = \"banana,,,,,ssqqqww.....\"\n",
    "x = txt.lstrip(\",.qsw\")\n",
    "print(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11008a94",
   "metadata": {},
   "source": [
    "#### Using the `with` function\n",
    "\n",
    "THe With function is designed to provide much cleaner syntax and exception handling when you are working with code. That explains why it’s good practice to use them with a statement where applicable. This is helpful because using this method any files opened will be closed automatically after one is done, so auto-cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a62ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code to illustrate with()\n",
    "with open(\"samplefile.txt\") as file: \n",
    "    data = file.read()\n",
    "# do something with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533eb90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code to illustrate with() alongwith write()\n",
    "with open(\"samplefile.txt\", \"w\") as f:\n",
    "    f.write(\"Hello World. This is an example and this is!!!\")\n",
    "#This will overwrite what was there before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af89c1e9",
   "metadata": {},
   "source": [
    "#### Using the `split()` in file handling\n",
    "\n",
    "We can also split lines using file handling in Python. This splits the variable when space is encountered. You can also split using any characters as we wish. Here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f327f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code to illustrate split() function\n",
    "with open(\"samplefile.txt\", \"r\") as file:\n",
    "    data = file.readlines()\n",
    "    for line in data:\n",
    "        word = line.split()\n",
    "        print (word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e899b5",
   "metadata": {},
   "source": [
    "## Finding Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1963fdb",
   "metadata": {},
   "source": [
    "#### Listing a directory\n",
    "\n",
    "Before you can manipulate a file or folder you first need to know what a folder contains. To do that lets create a functions that will assist us in listing the file within the folder that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb910527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#We are passign the variable that represente \n",
    "#the name of the folder we want to list as trhe function parameter\n",
    "def list_directory(folder):\n",
    "    #We need to use the for loop where cf is the current file within\n",
    "    #the folder. This will help us to retrive the list of files that\n",
    "    #the folder contains by using the os.listdir method and passing the\n",
    "    #name of the folder we want to list\n",
    "    for cf in os.listdir(folder):\n",
    "        #and then display the names of each of the file within the folder\n",
    "        #by printing out the file names\n",
    "        print(cf)\n",
    "#That is all is it to list the content.\n",
    "#Then we can call the list_directory function and pass the folder\n",
    "#we want to read. In this case we want to list the files in a folder\n",
    "#which can be found within the current project directory. Otherwise,\n",
    "#You may have to pass the full path of the folder you want to read like\"\n",
    "#The os.listdir method makes the work simple to achieve\n",
    "list_directory('./filestoread/') #notice the ./ in the passing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de24a7",
   "metadata": {},
   "source": [
    "#### Using the string Method to look for filenames within the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcf2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will start by importing the OS library\n",
    "\n",
    "import os\n",
    "'''\n",
    "Now lets create a new function called stringsearchendswith\n",
    "Then pass the folder name as well as the search criteria\n",
    "'''\n",
    "def stringseachendswith(folder, searchstring):\n",
    "    #The we need to get the list of files contained in a folder by listing the files within the specific folder\n",
    "    #This can be achieved by using the OS.listdir method\n",
    "    for cf in os.listdir(folder):\n",
    "        #Once we loop through the list file, we need to check whether the current files matches our search criteria\n",
    "        #We can do this by using the endswith methods. The endswith method checks whether the current file ends with\n",
    "        #the substring criteria and if that is true, we simply print the names of the files that match the search criteria\n",
    "        if cf.endswith(searchstring):\n",
    "            print(cf)\n",
    "'''\n",
    "There is another way to check whether the search string matches the\n",
    "search criteria. We check at the begining of the string rather than the\n",
    "end of the string. We can create a new function called stringsearchstartswith \n",
    "'''\n",
    "def stringsearchstartswith(folder, searchstring):\n",
    "    #the next thing to do is to list the files we\n",
    "    #want to search in the folder using the os.listdir\n",
    "    #like we did before\n",
    "    for cf in os.listdir(folder):\n",
    "        #After looping through the file, we need to check whether\n",
    "        #The current file matches the search criteria using the startswith string method\n",
    "        #What this methods does is to check whether the current file starts with the substring\n",
    "        if cf.startswith(searchstring):\n",
    "            #If the search results returns true then we print out the name of the files that matches\n",
    "            print(cf)\n",
    "#To see this in action lets invoke the function one after the other.\n",
    "\n",
    "#stringseachendswith('./filestoread/', '.csv')\n",
    "stringsearchstartswith('./filestoread/', 'act_2019')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f2ffa",
   "metadata": {},
   "source": [
    "### Using the Python `fnmatch()` method to find file\n",
    "\n",
    "It is possible that by using the basic string methods, you may not find all the files that you need. As a result, Python has some alterniatives. One of them is the fnmatch method. So we are going to take a look at how to use the Python fnmatch to find file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad633625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to import the os and fnmatch modules\n",
    "import os, fnmatch\n",
    "#Then let's create a function call fnmatchsearch\n",
    "def fnmatchsearch(folder, searchstring): #seacrhstring = search criteria\n",
    "    #for each file found withing the folder\n",
    "    for cf in os.listdir(folder):\n",
    "        #we need to call the fnmatch function then pass the currentfile name and the search criterial\n",
    "        if fnmatch.fnmatch(cf, searchstring):\n",
    "            #If the results returns is true, then we print out the current file name\n",
    "            print(cf)\n",
    "#Now let's test it by passing the folder to inspect and also the search criteria. In this case all the files that has the\n",
    "#file name ending with .csv extension\n",
    "\n",
    "\n",
    "#fnmatchsearch('./filestoread/', '*.csv')\n",
    "\n",
    "'''\n",
    "One thing that makes the fnmatch great is that we can create more powerful search criteria instead of \n",
    "simply looking for criteria, we can use wildcard. For instance we can search for any file that starts with\n",
    "_data and also have the .csv extension\n",
    "'''\n",
    "\n",
    "#fnmatchsearch('./filestoread/', '*_data.csv')\n",
    "'''\n",
    "You can also search for in the same way and include another wild card by saying get me file \n",
    "that includes 2 as part of its name\n",
    "'''\n",
    "#fnmatchsearch('./filestoread/', '*2*.csv')\n",
    "\n",
    "'''\n",
    "We can also perform some advanced pattern matching with fnmatch. In this case, we will search for file\n",
    "that start with any string but contains the _data substring and followed by any other substring and of any file type\n",
    "'''\n",
    "#fnmatchsearch('./filestoread/', '*_data*.*')\n",
    "\n",
    "'''\n",
    "Now let's try with a different string criteria. I will just add another underscore after the word data. This means\n",
    "only file names that include _data_ would be returned\n",
    "'''\n",
    "#fnmatchsearch('./filestoread/', '*_data_*.*')\n",
    "'''\n",
    "lets start with a different criteria. We only want the file that include the word 2.\n",
    "'''\n",
    "#fnmatchsearch('./filestoread/', '*2_*_*.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce144911",
   "metadata": {},
   "source": [
    "#### Using the `glob()` function for pattern matching to search for files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f76414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def globpattern_match(folder, searchstring):\n",
    "    #The first thing we want to do is to get the path for the folder we want to inspect\n",
    "    #Then call the glob method of the path object\n",
    "    path = Path(folder)\n",
    "    for x in path.glob(searchstring):\n",
    "        print(x)\n",
    "'''\n",
    "This search criteria indicates that we are looking for files that start with any substring\n",
    "has 2 as part of their file name and has extension that starts with the letter c\n",
    "'''\n",
    "#globpattern_match('./filestoread/', '*2*.c*')\n",
    "\n",
    "#Now lets check in the subfolder\n",
    "globpattern_match('./filestoread/subfolder', '*_data_*.c*')\n",
    "\n",
    "#glob_match('./filestoread/subfolder', '*1_t*data_*c*.t*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce0f8e2",
   "metadata": {},
   "source": [
    "## Working with Files and Folder\n",
    "\n",
    "Welcome back, in this session we will learn how to work with files and folders as part of daily operations. We will learn:\n",
    "\n",
    "1. How to get file attributes\n",
    "2. How to traverse and navigate a directory\n",
    "3. How to use python to copy files\n",
    "4. how to move files, renaming files and deleting files\n",
    "\n",
    "OK let's jump right into it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3bee17",
   "metadata": {},
   "source": [
    "#### Getting the File attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee6962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def return_date(timestmp): #all this function do is to return the current utc date time\n",
    "    return datetime.utcfromtimestamp(timestmp).strftime('%d %m %Y')\n",
    "\n",
    "def display_file_attrs(folder):\n",
    "    with os.scandir(folder) as dir:\n",
    "        for file_item in dir:\n",
    "            if file_item.is_file():\n",
    "                file_attribute = file_item.stat()\n",
    "                print(f'Modified Date {return_date(file_attribute.st_mtime)} {file_item.name}')\n",
    "\n",
    "display_file_attrs('./filestoread/subfolderfortraining/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc3bfa7",
   "metadata": {},
   "source": [
    "#### Traversing/Navigating a Directory\n",
    "\n",
    "Traversing or navigating a directory is done by looping through the directory, the folder and the files that are \n",
    "within the the os.walk method for the folder we want to traverse or navigate in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c20db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def traversenaviagte(folder):\n",
    "    for folderpath, dirs, files in os.walk(folder):\n",
    "        print(f'This is a Folder: {folderpath}') #Lets print out the folder path\n",
    "        for file in files: #Loop through each of the file returned\n",
    "            print(f'\\t{file}')\n",
    "\n",
    "traversenaviagte('./filestoread/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e2343",
   "metadata": {},
   "source": [
    "#### Copying Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def copyfile(source, destination):\n",
    "    shutil.copy(source, destination)\n",
    "\n",
    "def copyfoldercontent(source, destination):\n",
    "    shutil.copytree(source, destination)\n",
    "\n",
    "#copyfile('./filestoread/MikeTroutData.csv', './filestoread/subfolderfortraining/')\n",
    "copyfoldercontent('./filestoread/dataset/', './filestoread/subfolderfortraining/newdatasetfolder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ce840f",
   "metadata": {},
   "source": [
    "#### Moving Files same as cutting file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8db105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def movefile(source, destination):\n",
    "    shutil.move(source, destination)\n",
    "\n",
    "#movefile('./filestoread/MikeTroutData.csv', './filestoread/subfolderfortraining/MikeTroutData.csv')\n",
    "#movefile('./filestoread/dataset/', './filestoread/subfolderfortraining/') #Move entire folder\n",
    "#movefile('./filestoread/subfolderfortraining/dataset/', './filestoread/') #Move the folder back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f96ff5",
   "metadata": {},
   "source": [
    "#### Renaming Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b86ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "#This is one name of renaming file\n",
    "def filerename(source, destination): \n",
    "    os.rename(source, destination)\n",
    "\n",
    "    #This is another way of renaming name\n",
    "def renamefile(source, destination):\n",
    "    file = Path(source)\n",
    "    file.rename(destination)\n",
    "\n",
    "#filerename('./filestoread/MikeTroutData.csv', './filestoread/MikeTroutDataRename.csv')\n",
    "filerename('./filestoread/MikeTroutDataRename.csv', './filestoread/MikeTroutData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393197da",
   "metadata": {},
   "source": [
    "#### Deleting File\n",
    "\n",
    "One important aspect of working with files is the ability to delete them when the need arises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22679f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genericpath import isfile\n",
    "import os\n",
    "\n",
    "def deletefile(file): #pass the name of the file to delete\n",
    "    if os.path.isfile(file): #verify that the file you want to delete is actually a file\n",
    "        #Lets wrap the logic of the code around the try ... except startement. We will discuss this latter\n",
    "        try:\n",
    "            os.remove(file)\n",
    "        except OSError as e:\n",
    "            print(f'Error: {file} : {e.strerror}')\n",
    "    else:\n",
    "        print(f'Error: {file} is not a valid file or the file is no longer existing')\n",
    "\n",
    "deletefile('./filestoread/MikeTroutData - Copy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43060939",
   "metadata": {},
   "source": [
    "## Working with Archive files in Python\n",
    "\n",
    "An archive is a collection of compressed files. Like your zipped files and rar files which takes less space on your computer. Zipped file is the most archiving file format.\n",
    "\n",
    "In this session, we will begin by learning how to create a zip file. \n",
    "Then we will learn how to add files to an existing zipped files\n",
    "We will see how to read the content of a zipped file\n",
    "And finally we will see how to extract the content of a zipped file.\n",
    "\n",
    "Let's get started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9427b98c",
   "metadata": {},
   "source": [
    "#### Creating a Zipped File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be0a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "filestozip = ['./binarizedcsvfile', \n",
    "    './diabetes-data.csv', \n",
    "    './normalizedcsvfile', \n",
    "    './robustscaledcsvfile']\n",
    "\n",
    "def createzip(nameofsipfile, filestocompress, opt): #He we pass as parameters the name of the zip file (zipf) \n",
    "    #the list of iles to compress and some additional zip options\n",
    "    with zipfile.ZipFile(nameofsipfile, opt, allowZip64=True) as archive:\n",
    "        for files in filestocompress:\n",
    "            archive.write(files)\n",
    "\n",
    "createzip('./filestoread/extensivepythonfundamentals.zip', filestozip, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a0fd45",
   "metadata": {},
   "source": [
    "#### Adding file to exisiting zipped File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ae22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "filestoadd = ['./Nwama_Grace_Reference_Letter.docx',\n",
    "             './Ogunleye Documents PP.docx']\n",
    "\n",
    "def addtozippedfile(nameofexistingzippedfile, listfilestoadd, opt):\n",
    "    with zipfile.ZipFile(nameofexistingzippedfile, opt) as archive:\n",
    "        for file in listfilestoadd: #for each file found within the list of files to the existing zipped file\n",
    "            namelist = archive.namelist() #invoke the name list method from archive\n",
    "            if not file in namelist: #if the name of the file we want to add to the zipped file does not exist\n",
    "                #Add the current file to the existing zip by calling the write method of the zip file and \n",
    "                #pass the name of the current file\n",
    "                archive.write(file)\n",
    "            else: #Else if the current file already exist in the zipped file, then we can print out the message\n",
    "                #that this file already exist within the zip\n",
    "                print(f'File exists in zip: {file}')\n",
    "\n",
    "addtozippedfile('./filestoread/extensivepythonfundamentals.zip', filestoadd, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444f4e89",
   "metadata": {},
   "source": [
    "#### Reading a zipped file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dfaed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def readzippedfile(nameofthezippedfiletoread): #Here we pass the name of the zipped file that we want to read\n",
    "    with zipfile.ZipFile(nameofthezippedfiletoread, 'r') as archive: #OPen the zipped file in read mode\n",
    "        namelist = archive.namelist() #We will check what files are available within he zipped file\n",
    "        for filelist in namelist: #for each file within the archive call the getinfor method from archive\n",
    "            zipinfo = archive.getinfo(filelist) #And pass the name of the current file\n",
    "            print(f'{filelist}: filesize => {zipinfo.file_size} bytes, compressed size => {zipinfo.compress_size} bytes') #Then print the information\n",
    "            #about the zip, such as the file size and the compressed size\n",
    "\n",
    "readzippedfile('./filestoread/extensivepythonfundamentals.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1c10d9",
   "metadata": {},
   "source": [
    "#### Extracting the content of a Zipped File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff6b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "#This will only extract one file\n",
    "def extractzippedfile(nameofthezippedfiletoextract, nameofthefilewithinthezip, locationtoextractfileto):\n",
    "    with zipfile.ZipFile(nameofthezippedfiletoextract, 'r') as archive:\n",
    "        archive.extract(nameofthefilewithinthezip, path=locationtoextractfileto) #Then invoke the extract method\n",
    "\n",
    "#if we want to extract all the files contained in the zipped file\n",
    "def extractallzippedfile(nameofthezippedfiletoextract, locationtoextractfileto):\n",
    "    with zipfile.ZipFile(nameofthezippedfiletoextract, 'r') as archive:\n",
    "        archive.extractall(path=locationtoextractfileto)\n",
    "\n",
    "#extractzippedfile('./filestoread/extensivepythonfundamentals.zip', 'diabetes-data.csv', 'filestoread/extractedfolder')\n",
    "extractallzippedfile('./filestoread/extensivepythonfundamentals.zip', 'filestoread/extractedfolder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a794d13",
   "metadata": {},
   "source": [
    "## Reading and Writing Files\n",
    "\n",
    "In this session, we will explore how to work with text files, how to work with comma separated (CSV) files, We will also explore how to work with Javascript Object Notation (JSON) Files. Finally we will learn how to persist binary files through the use of Python Pickle module. Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07f5e7a",
   "metadata": {},
   "source": [
    "#### Working with Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffc0d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readtext(nameofthefiletoread):\n",
    "    with open(nameofthefiletoread) as file:\n",
    "        print(file.read())\n",
    "\n",
    "def readtextlinebyline(nameofthefiletoread):\n",
    "    with open(nameofthefiletoread) as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            print(line, end='')\n",
    "            line = file.readline()\n",
    "\n",
    "def writenewtext(nameofthefiletoread, str):\n",
    "    with open(nameofthefiletoread, 'w', encoding='utf-8') as file:\n",
    "        file.write(str)\n",
    "\n",
    "def appendlinetotext(nameofthefiletoread, str):\n",
    "    with open(nameofthefiletoread, 'a', encoding='utf-8') as file:\n",
    "        file.write('\\n')\n",
    "        file.write(str)\n",
    "\n",
    "#readtext('./extensivepythonfundamentals.txt')\n",
    "#readtextlinebyline('./extensivepythonfundamentals.txt')\n",
    "#writenewtext('./sample.txt', 'this is a just to test the file...')\n",
    "#appendlinetotext('./sample.txt', 'this is just to append an extra line')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7821bdc5",
   "metadata": {},
   "source": [
    "#### Working with the CSV files\n",
    "\n",
    "Lets see how to work with the Comma Separated Files also known as csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ec8bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def readcsvfile(nameofcsvfile, delimiter): #Pass the name of the csv file to read and the delimiter\n",
    "    with open(nameofcsvfile) as csvfile: #Now let's open the csv files and pass the name of the file we want to open\n",
    "        cnt = -1 #lets create a counter and initiate it to -1\n",
    "        rows = csv.reader(csvfile, delimiter=delimiter) #And also lets read the rows from the csv by invoking the reader method of the csv\n",
    "        for row in rows: #Then we need to loop across all the row of the csv files  \n",
    "            if cnt == -1: #if the value of the counter == -1 then\n",
    "                print(f'{\" | \".join(row)}') #print the header of the csv file\n",
    "            else: #otherwise print each of the values for the current role\n",
    "                print(f'{row[0]} | {row[1]} | {row[2]} | {row[3]}') #Each record value is accessed using an array index\n",
    "            cnt += 1 #for each loop we increment the counter. The reason we are using the counter is because we want to \n",
    "            #be able to differentiate between the header and the actual data\n",
    "        print(f'{cnt} lines')\n",
    "\n",
    "def writetocsvfile(nameofcsvfile, header, row):\n",
    "    with open(nameofcsvfile, mode='w', newline='') as csvfile: #We need to open the csv file in write mode\n",
    "        writer = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(header)\n",
    "        writer.writerow(row)\n",
    "        \n",
    "#readcsvfile('./filestoread/act_2019_ca.csv', ',')\n",
    "#writetocsvfile('./personalinfo.csv', \n",
    "#['Firstname', 'lastname', 'Date of Birth', 'Phone Number'], \n",
    "#['Olalekan Samuel', 'Ogunleye', '14/07/1976', '08145674532'])\n",
    "readcsvfile('./personalinfo.csv', ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a890fb",
   "metadata": {},
   "source": [
    "#### Work with JSON Files\n",
    "\n",
    "Lets explore how we can work with Javascript Object Notation, also know as json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8977154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def readjson(nameofjsonfile, printnice, sort): #Pass the name of Json file as parameter and also\n",
    "    with open(nameofjsonfile) as jsonfile:\n",
    "        data = json.load(jsonfile)\n",
    "        print(json.dumps(data, sort_keys=sort, indent=4) \n",
    "        if printnice else data)\n",
    "\n",
    "#def update_author_json(nameofjsonfile, arr_name, pos, key, value):\n",
    " #   with open(nameofjsonfile, 'r') as read_file:\n",
    " #       data = json.load(read_file)\n",
    "  #      data[arr_name][pos][key] = value\n",
    "  #      with open(nameofjsonfile, 'w') as write_file:\n",
    "  #          json.dump(data, write_file)\n",
    "\n",
    "readjson('./filestoread/esp-abuse.json', True, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2014438",
   "metadata": {},
   "source": [
    "#Persisting Python Object into Binary Files.\n",
    "\n",
    "Persisiting Objects is simply saving internal state to disk, a database or over the network. \n",
    "The first question you may be asking yourself is why do we need to persist python objects. Well as a developer, it is import to serve the internal state of your application to disk, the database or send the details over the network. Thi is why persisting an object might come in handy.\n",
    "\n",
    "So let's start by importing the pickle module.\n",
    "\n",
    "We will create a Person class that includes age name, kids, employers, and shoes sizes properties.\n",
    "\n",
    "The idea behind this is that we will use the Python pickle module to serialize this class, and stor the data in a binary file.\n",
    "\n",
    "###### This is for `def serialize(obj)`\n",
    "To do that we will create a serialize function to which we pass an object. This function will invoke the pickle. dumps method, which will convert the object that we are passing into binary object using the serialization protocols. We will then print out the serialized object and return it.\n",
    "\n",
    "###### This is for `def  deserialize(obj)`\n",
    "We will also do the reverse, where we will take the binary object and covert it into a Python Object. To do this, we will invoke the load method in the pickle module and pass the binary object and return the python object. We can then print and return it.\n",
    "\n",
    "###### This is for `def deserialize_prev_employers(obj)`\n",
    "We can also create another function to specifically desrialize a particular properties of the object, lets say in this case Previous employees attribute of the person. By can do this by using the same laod method in the pickle module while we pass the binary object and print the previous employers properties from the desrialized object\n",
    "\n",
    "###### This is for `def obj_to_file(fn, obj)`\n",
    "\n",
    "We also need to write a function that will save the object into a binary file. We can do this by opening the file in write binary mode and call the dump method in the pickle module, and pass the object, the reference to the file and the serialization protocol.\n",
    "\n",
    "###### This is for `def file_to_obj`\n",
    "Finally we need to perform the opposite by taking the binary file and convert it into a python object. To do this, we need to open the Object in read binary mode and then call the load method of the pickle module while we pass the reference to the binary file. Then we can print the deserialize Python object and return it.\n",
    "\n",
    "#### This is for running the code now. Say this after you have written the code and want to run it\n",
    "We can then proceed from there by invoking the serialize function by passing the Person class into it as a parameter. Then we can call the deserialize function and then pass the serialized object into it. We can also invoke the deserialize employers function and also passing the serialized object.\n",
    "\n",
    "Once we execute the script, we can see the output of the serialized object that was first executed, and then we can also see the deserialized object that followed, by the representation of the deserialized previous employers.\n",
    "\n",
    "Now we need to test the object to file and file to object function. To the object to file all we need to do is to pass the name of the result in binary file where we want the instance of the Person class to be written to and then pass the person class as the second parameter.\n",
    "\n",
    "Then we will pass the serialized object of that person class to the file object function which will then read the content of the resulting binary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b9a7a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Employee_Details object at 0x0000028BC7BB03D0>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "class Employee_Details:\n",
    "    age = 44\n",
    "    name = 'Olalekan Samuel'\n",
    "    dependants = ['Sandy', 'Mandy', 'Wendy']\n",
    "    prev_employers = {'NIOH': 2022, 'CSIR': 2014, 'MONASH': 2008}\n",
    "    prev_salaries = (70000, 85000)\n",
    "\n",
    "'''\n",
    "To do that we will create a serialize function to which we pass an object. This function will invoke the pickle.dumps\n",
    "method, which will convert the object that we are passing into binary object using the serialization protocols. \n",
    "We will then print out the serialized object and return it.\n",
    "'''\n",
    "def serialize(obj):\n",
    "    pickled = pickle.dumps(obj, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f'Serialized object: \\n{pickled}\\n')\n",
    "    return pickled\n",
    "'''\n",
    "We will also do the reverse, where we will take the binary object and covert it into a Python Object. To do this, \n",
    "we will invoke the load method in the pickle module and pass the binary object and return the python object. \n",
    "We can then print and return it.\n",
    "'''\n",
    "def deserialize(obj):\n",
    "    unpickled = pickle.loads(obj)\n",
    "    print(f'Deserialized: \\n{unpickled}\\n')\n",
    "\n",
    "'''\n",
    "We can also create another function to specifically desrialize a particular properties of the object, lets say in \n",
    "this case Previous employees attribute of the person. By can do this by using the same laod method in the pickle \n",
    "module while we pass the binary object and print the previous employers properties from the desrialized object\n",
    "'''\n",
    "def deserialize_prev_employers(obj):\n",
    "    unpickled = pickle.loads(obj)\n",
    "    print(f'Deserialized Previous Employers: \\n{unpickled.prev_employers}\\n')\n",
    "\n",
    "'''\n",
    "We also need to write a function that will save the object into a binary file. We can do this by opening the \n",
    "file in write binary mode and call the dump method in the pickle module, and pass the object, the reference to \n",
    "the file and the serialization protocol.\n",
    "'''\n",
    "def obj_to_file(fn, obj):\n",
    "    with open(fn, 'wb') as pf:\n",
    "        pickle.dump(obj, pf, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "'''\n",
    "Finally we need to perform the opposite by taking the binary file and convert it into a python object. To do this, \n",
    "we need to open the Object in read binary mode and then call the load method of the pickle module while we pass \n",
    "the reference to the binary file. Then we can print the deserialize Python object and return it.\n",
    "'''       \n",
    "def file_to_obj(fn, obj):\n",
    "    with open(fn, 'rb') as pf:\n",
    "        obj = pickle.load(pf)\n",
    "        print(obj)\n",
    "        return obj\n",
    "\n",
    "#pickled = serialize(Employee_Details())\n",
    "#deserialize(pickled)\n",
    "#deserialize_prev_employers(pickled)\n",
    "\n",
    "#obj = obj_to_file('./filestoread//employee_details.xyz', Employee_Details())\n",
    "#employee = file_to_obj('./filestoread//employee_details.xyz', obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97739fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
